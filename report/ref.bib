@article{intriguing-properties-of-neural-networks,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{explaining-and-harnessing-adversarial-examples,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{glorot-understanding-deep-nn-training,
  title={Understanding the difficulty of training deep feedforward neural networks.},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Aistats},
  volume={9},
  pages={249--256},
  year={2010}
}

@inproceedings{going-deeper-with-convolutions,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1--9},
  year={2015}
}

@article{multi-column-neural-network-gtsrb,
	author		= {Cireşan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, Jürgen},
	title		= {{Multi-column deep neural network for traffic sign classification}},
	journal		= {Neural Networks},
	year		= {2012},
	volume		= {32},
	pages		= {333-338},
	publisher	= {Elsevier}
}

@article{cirecsan2012multi,
  author={Cire{\c{s}}An, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, J{\"u}rgen}
}

@article{gtsrb-description,
	title = "Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition ",
	journal = "Neural Networks ",
	volume = "32",
	number = "",
	pages = "323 - 332",
	year = "2012",
	note = "Selected Papers from \{IJCNN\} 2011 ",
	issn = "0893-6080",
	doi = "http://dx.doi.org/10.1016/j.neunet.2012.02.016",
	url = "http://www.sciencedirect.com/science/article/pii/S0893608012000457",
	author = "J. Stallkamp and M. Schlipsing and J. Salmen and C. Igel",
	keywords = "Traffic sign recognition",
	keywords = "Machine learning",
	keywords = "Convolutional neural networks",
	keywords = "Benchmarking ",
	abstract = "Traffic signs are characterized by a wide variability in their visual appearance in real-world environments. For example, changes of illumination, varying weather conditions and partial occlusions impact the perception of road signs. In practice, a large number of different sign classes needs to be recognized with very high accuracy. Traffic signs have been designed to be easily readable for humans, who perform very well at this task. For computer systems, however, classifying traffic signs still seems to pose a challenging pattern recognition problem. Both image processing and machine learning algorithms are continuously refined to improve on this task. But little systematic comparison of such systems exist. What is the status quo? Do today’s algorithms reach human performance? For assessing the performance of state-of-the-art machine learning algorithms, we present a publicly available traffic sign dataset with more than 50,000 images of German road signs in 43 classes. The data was considered in the second stage of the German Traffic Sign Recognition Benchmark held at \{IJCNN\} 2011. The results of this competition are reported and the best-performing algorithms are briefly described. Convolutional neural networks (CNNs) showed particularly high classification accuracies in the competition. We measured the performance of human subjects on the same data—and the \{CNNs\} outperformed the human test persons. "
}

@inproceedings{imagenet-large-scale-hierarchical-image-database,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={248--255},
  year={2009},
  organization={IEEE}
}

@techreport{coil-100,
	title		= {Columbia Object Image Library (COIL-100)},
	author		= {Nene, Sameer A and Nayar, Shree K and Murase, Hiroshi and others},
	year		= {1996},
	institution	= {Technical report CUCS-005-96}
}

@article{estimating-face-orientation-inria,
	author       = "Gourier, Nicolas and Hall, Daniela and Crowley, James L.",
	title        = {{Estimating Face orientation from Robust Detection of Salient Facial Structures}},
	journal      = {FG Net Workshop on Visual Observation of Deictic Gestures (POINTING)},
	year         = "2004",
	note         = "\url{http://www-prima.inrialpes.fr/prima/pub/Publications/2004/GHC04/}"
}

@techreport{columbia_object_image_library,
	author 		= {S. A. Nene and S. K. Nayar and H. Murase},
	title 		= {{C}olumbia {O}bject {I}mage {L}ibrary ({C}{O}{I}{L}-100)},
	booktitle 	= {Technical Report, Department of Computer Science, Columbia University CUCS-006-96},
	month 		= {Feb},
	year 		= {1996}
}

@article{deep-learning,
	author={LeCun, Yann
	and Bengio, Yoshua
	and Hinton, Geoffrey},
	title={Deep learning},
	journal={Nature},
	year={2015},
	month={May},
	day={28},
	publisher={Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	volume={521},
	number={7553},
	pages={436-444},
	abstract={Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	note={Insight},
	issn={0028-0836},
	url={http://dx.doi.org/10.1038/nature14539}
}

@article{dynamic-field-theory-movement-preparation,
  title={Dynamic field theory of movement preparation.},
  author={Erlhagen, Wolfram and Sch{\"o}ner, Gregor},
  journal={Psychological review},
  volume={109},
  number={3},
  pages={545},
  year={2002},
  publisher={American Psychological Association}
}


@article{neural-representation-and-neural-computation,
  title={Neural representation and neural computation},
  author={Churchland, Patricia Smith and Sejnowski, Terrence J},
  journal={Philosophical Perspectives},
  volume={4},
  pages={343--382},
  year={1990},
  publisher={JSTOR}
}

@online{breaking-linear-classifiers-on-imgagenet,
  author  = "Andrej Karpathy",
  title   = "Breaking Linear Classifiers on ImageNet",
  year    = "2015",
  urlseen = "21-11-16",
  url     = "http://karpathy.github.io/2015/03/30/breaking-convnets/"
}

@online{caffe-cross-entropy,
 author  = "BVLC",
 title   = "Documentation on cross entropy in Caffe software",
 year    = "2016",
 urlseen = "18-11-16",
 url     = "http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1MultinomialLogisticLossLayer.html"
}

@online{how-to-trick-neural-network-panda-to-vulture,
	author	= "Julia Evans",
	title	= "How to trick a neural network into thinking a panda is a vulture",
	year	= "2015",
	urlseen	= "01-07-16",
	url		= "https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture"
}
