{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import caffe\n",
    "import adex.core\n",
    "import adex.googlenet\n",
    "\n",
    "CAFFE_ROOT = '/home/chrisbot/Projects/caffe'\n",
    "DATA_ROOT = '/media/sf_Masterarbeit/data/ILSVRC2012_img_train_panda'\n",
    "AE_ROOT = '/media/sf_Masterarbeit/data/ILSVRC2012_img_train_panda_AE'\n",
    "\n",
    "AE_GRAD_COEFF = 0.9\n",
    "ITERATIONS = 10\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "SAMPLE_COUNT = 2\n",
    "SUCCESS_THRESHOLD = 0.5\n",
    "FAILURE_THRESHOLD = 0.1\n",
    "\n",
    "net = adex.googlenet.load_model(CAFFE_ROOT, BATCH_SIZE)\n",
    "labels = adex.googlenet.load_labels(CAFFE_ROOT)\n",
    "transformer = adex.googlenet.build_transformer(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna prepare the data by reading all .csv files in the *AE_ROOT* folder. They will be split into a success and a failure set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_data = []\n",
    "for csvpath in glob.glob(AE_ROOT + '/*history.csv'):\n",
    "    with open(csvpath) as csv_file_desc:\n",
    "        reader = csv.reader(csv_file_desc)\n",
    "        for row in reader:\n",
    "            csv_data.append(row)\n",
    "csv_data = [[fname, target_cl, float(certainty), int(num_iter)] for fname, target_cl, certainty, num_iter in csv_data]\n",
    "csv_data = [row for row in csv_data if row[0][:9] != row[1]] # Exclude if original class = target class\n",
    "random.shuffle(csv_data) # bring data into random order\n",
    "\n",
    "csv_successes, csv_failures = [], []\n",
    "for row in csv_data:\n",
    "    if row[2] >= SUCCESS_THRESHOLD:\n",
    "        csv_successes.append(row)\n",
    "    elif row[2] < FAILURE_THRESHOLD:\n",
    "        csv_failures.append(row)\n",
    "\n",
    "csv_successes = csv_successes[:SAMPLE_COUNT] # Ensure a maximum of SAMPLE_COUNT images each\n",
    "csv_failures = csv_failures[:SAMPLE_COUNT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*make_ae* is a wrapper function for *adex.core.make_adversarial* that performs a fixed number of steps, regardless of confidence, and returns the confidence progress over time. *record_progress* records these progesses for all images in *csv_list* in a 2-dimensional numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_ae(net, data, desired_labels, ae_grad_coeff, iterations):\n",
    "    progress = np.zeros(shape=(iterations))\n",
    "    ae_data = data.copy()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        ae_data, confidence, num_it = adex.core.make_adversarial(net, ae_data, desired_labels, ae_grad_coeff, 100, 1)\n",
    "        progress[i] = confidence\n",
    "    \n",
    "    return progress\n",
    "\n",
    "def record_progress(csv_list):\n",
    "    progress_record = np.zeros(shape=(ITERATIONS))\n",
    "    \n",
    "    for orig_filename, target_class, _, _ in csv_list:\n",
    "        orig_class = orig_filename[:9]\n",
    "\n",
    "        image = caffe.io.load_image(DATA_ROOT + '/' + orig_class + '/' + orig_filename)\n",
    "        image = transformer.preprocess('data', image)\n",
    "        image = np.expand_dims(image, 0)\n",
    "\n",
    "        label = adex.googlenet.get_label_from_class_name(labels, target_class)\n",
    "        label = np.array([label])\n",
    "\n",
    "        progress = make_ae(net, image, label, AE_GRAD_COEFF, ITERATIONS)\n",
    "        progress_record = np.vstack([progress_record, progress])\n",
    "    \n",
    "    return progress_record[1:] # Skip the first because it is all zeros (initialization for stacking)\n",
    "\n",
    "success_progress = record_progress(csv_successes)\n",
    "failure_progress = record_progress(csv_failures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write the data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(AE_ROOT + '/' + 'success_progress.csv', 'w') as file_desc:\n",
    "    writer = csv.writer(file_desc)\n",
    "    for row in csv_successes:\n",
    "        writer.writerow(row)\n",
    "with open(AE_ROOT + '/' + 'failure_progress.csv', 'w') as file_desc:\n",
    "    writer = csv.writer(file_desc)\n",
    "    for row in csv_failures:\n",
    "        writer.writerow(row)\n",
    "np.save(AE_ROOT + '/' + 'success_progress.npy', success_progress)\n",
    "np.save(AE_ROOT + '/' + 'failure_progress.npy', failure_progress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
