{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import caffe\n",
    "import adex.core\n",
    "import adex.coil\n",
    "\n",
    "AE_GRAD_COEFF = 0.1\n",
    "CONFIDENCE_TARGET = 0.9\n",
    "MAX_ITERATIONS = 250\n",
    "ORIG_CLASS_LIMIT = 50\n",
    "TARGET_CLASS_LIMIT = 50\n",
    "\n",
    "#CAFFE_ROOT = '/home/chrisbot/Projects/caffe'\n",
    "LAYOUT_PATH = '/media/sf_Masterarbeit/master-thesis/coil-100/network_normal_deploy.prototxt'\n",
    "WEIGHT_PATH = '/media/sf_Masterarbeit/master-thesis/coil-100/snapshots/normal_iter_75600.caffemodel'\n",
    "#DATA_ROOT = '/media/sf_Masterarbeit/data/COIL100'\n",
    "ORIGINAL_LIST_PATH = '/media/sf_Masterarbeit/data/COIL100/train_images_labeled.txt'\n",
    "OUTPUT_ROOT = '/media/sf_Masterarbeit/data/COIL100_fullres_AE_{0}'.format(AE_GRAD_COEFF)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "net = adex.coil.load_model(LAYOUT_PATH, WEIGHT_PATH, BATCH_SIZE)\n",
    "shape = list(net.blobs['data'].data.shape)\n",
    "shape[0] = BATCH_SIZE\n",
    "net.blobs['data'].reshape(*shape)\n",
    "net.blobs['prob'].reshape(BATCH_SIZE, )\n",
    "net.reshape()\n",
    "transformer = adex.coil.build_transformer(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5400 images in 100 classes\n",
      "Using 1 original classes\n",
      "Using 100 target classes\n"
     ]
    }
   ],
   "source": [
    "# Returns a dict with the class id as key and (full_path, class, instance_name) as value\n",
    "def get_image_dict(path):\n",
    "    image_dict = {}\n",
    "    with open(path) as image_list_file:\n",
    "        for line in image_list_file:\n",
    "            line = line.strip()\n",
    "            img_class = line.split()[-1].strip()\n",
    "            img_path = line[:-len(img_class)].strip()\n",
    "            img_class = int(img_class) - 1\n",
    "            img_instance = img_path[:-len(img_path.split('.')[-1]) - 1] # cut extension irrespective of its length\n",
    "            img_instance = img_instance.split('/')[-1]\n",
    "            \n",
    "            try:\n",
    "                image_dict[img_class].append((img_path, img_class, img_instance))\n",
    "            except KeyError:\n",
    "                image_dict[img_class] = [(img_path, img_class, img_instance)]\n",
    "    return image_dict\n",
    "image_dict = get_image_dict(ORIGINAL_LIST_PATH)\n",
    "\n",
    "#image_dict = get_image_dict(DATA_ROOT)\n",
    "sys.stdout.write('Found {0} images in {1} classes\\n'.format(\n",
    "        sum(map(lambda x: len(x), image_dict.values())), len(image_dict.keys())))\n",
    "\n",
    "orig_class_list = image_dict.keys()[:]\n",
    "target_class_list = image_dict.keys()[:]\n",
    "random.shuffle(orig_class_list)\n",
    "random.shuffle(target_class_list)\n",
    "orig_class_list = orig_class_list[:ORIG_CLASS_LIMIT]\n",
    "target_class_list = target_class_list[:TARGET_CLASS_LIMIT]\n",
    "sys.stdout.write('Using {0} original classes\\n'.format(len(orig_class_list)))\n",
    "sys.stdout.write('Using {0} target classes\\n'.format(len(target_class_list)))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(OUTPUT_ROOT)\n",
    "except OSError:\n",
    "    pass # Directory already exists\n",
    "\n",
    "for orig_class in orig_class_list:\n",
    "    class_representative_path, _, class_representative_instance_name = random.choice(image_dict[orig_class])\n",
    "    \n",
    "    # Prepare output directory\n",
    "    output_dir = OUTPUT_ROOT + '/' + str(orig_class) + '_' + str(class_representative_instance_name)\n",
    "    try:\n",
    "        os.mkdir(output_dir)\n",
    "    except OSError:\n",
    "        pass # Directory already exists\n",
    "    \n",
    "    history = []\n",
    "    for target_class in target_class_list:\n",
    "        image = adex.coil.load_image(transformer, class_representative_path)\n",
    "        target_label = np.array([target_class])\n",
    "        \n",
    "        adversarial_image, confidence, iterations = adex.core.make_adversarial(net, image, target_label, AE_GRAD_COEFF,\n",
    "                                                                               CONFIDENCE_TARGET, MAX_ITERATIONS)\n",
    "        \n",
    "        out_path = output_dir + '/' + str(target_class) + '.npy'\n",
    "        np.save(out_path, adversarial_image)\n",
    "        \n",
    "        # Add data to history\n",
    "        history.append( [orig_class, class_representative_path.split('/')[-1], target_class, confidence, iterations] )\n",
    "    \n",
    "    with open(OUTPUT_ROOT + '/' + str(orig_class) + '_' + str(class_representative_instance_name) + '_' + 'history.csv', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for target_class_history in history:\n",
    "            writer.writerow(target_class_history)\n",
    "    \n",
    "    # A bit of progress feedback\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
